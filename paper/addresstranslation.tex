% vim: tw=80 ai fdl=99 fo+=a
%
% $Id$
%

\section{Translating virtual to physical addresses}

\subsection{Motivation}

There are two obvious ways to extract useful information from physical
addressable memory:

\begin{itemize}

	\item It is possible to parse the operating systems internal data
	structures holding all relevant information about loaded drivers,
	running processes et al.
	
	\item It is possible to use the information that the operating system
	provides to the hardware to tell it about the virtual address spaces of
	each process.
	
\end{itemize}

The first scenario will not work between different operating systems and
architectures, it will be neccessary to write a parser for each combination of
them, possibly even for different versions of the same operating system.

The latter uses an information structure that only changes between different
architectures, as the architecture relies on it. Furthermore there is a well
defined algorithm for using this information (implemented in hardware in the
architecture, but well defined in the reference manuals for this architecture,
so system designers can provide valid data to the hardware).

On the other hand, the first approach will give much more information about the
system than the second, as we obtain all information directly from the kernel
structures, while using the second approach we only can enter virtual address
spaces of processes.

\cite{finding_digital_evidence_in_physical_memory:2006} is parsing
kernel-structs of windows and linux kernels. I will in the following use the
second approach for most attacks, as this seems to be more robust and
automatiseable. As the above mentioned paper is about \emph{finding an attacker}
and not \emph{attacking}, the forensic personell does know about the
architecture, the operating system and version and can build a copy of the
system to test its tools, while an attacker only can guess the architecture and
operating system and needs more robust tools for his attacks.  (Obviously this
is only a short-term argument, as an attacker can also write such tools for
\emph{all} OS version and architecture combinations... but the heck with
this...).

\subsection{Basic address translations}

\label{address_translation} All multitasking environments that fulfill current
requirements have to provide virtual address spaces for each running process or
thread. For performance and security reason this address translation from a
process's virtual address to an address valid in physical memory is normally
performed in hardware.  These mechanisms can include e.g. segmentation and
paging.

A normal process's memory is divisible into several blocks or \emph{segments}:
the \emph{code segment} contains all the code that may be run; the \emph{data
segment} contains the static data that is known at compile time, global
structures or deliberately allocated memory (including the heap); the
\emph{stack segment} contains the stack, including local variables.  On some
architectures, it is possible to assign segment descriptors, reffering to
defined memory regions, to segment registers.  This assignment will influence
the further behaviour of address translation: all addresses will from there on
be taken to be relative to the bound of the memory region specified by the
segment descriptor. This mechanism is called \emph{segmentation}.

\emph{Paging} will divide the virtual address space of a process into several
consecutive \emph{frames} of a specific page-size (typically 4096 bytes).
Virtual addresses can be split into frame number and frame offset; the frame
number is translated (mapped) via a translation table into a physical page
number and the frame offset is used as an offset into this physical page. If a
frame does not have a corresponding physical page, is is called to be unmapped.
Unmapped pages can be non-existing pages or can e.g, be swapped to slower media
like harddisks.

For a detailed description and discussion of these two important mechanisms, the
reader may reffer to a course on system programming, e.g.
\cite{rwth_syspro_scriptum:2002}.

\texttt{liblinear} provides a software solution for address translation. The
provided interface is similar to \texttt{libphysical}; it needs a physical
memory source (in form of a \texttt{physical\_handle}), and information about
the target architecture. It provides some functions to find address translation
tables in the raw memory and functions to use them to access the induced virtual
address space.



\subsection{Example implementation: IA32 backend for \texttt{liblinear}}

On the IA32 architecture, the CPU can run in various modes of operation; for
modern multitasking operating systems the \emph{protected mode} is the preferred
one.  The protected mode can use a two-level address translation: first it will
translate the \emph {logical address}, consisting of a segment selector (which
is an index into either the local or the global segment descriptor table) and an
offset to the \emph{linear address}.  The linear address is then translated via
paging to the \emph{physical address}. (The paging translation is optional and
needs to be enabled by setting a special flag in a control register of the CPU.)

\label{linux_gdt} A linux process runs in a simple 4GiB flat virtual address
space; no segmentation is required. Thus, linux will create (among others that
are not of interest for us) four special segments during boot-up: for each
privilege level (i.e. kernelspace and userspace), it will create segments for
both code and data. These four so called \emph{flat} segments will span the full
virtual address space of 4GiB, thus effectively elliminating segmentation. The
address of the \emph{global descriptor table}, holding the description of these
segments, is then loaded into the \emph{global descriptor table register} (GDTR)
and the specific segment registers are loaded with segment selectors refering to
the segments\footnote{This initialization is done in
\texttt{linux/arch/i386/kernel/head.S}, GDTs are defined at symbols
\texttt{boot\_gdt\_table} and \texttt{cpu\_gdt\_table}}.

The IA32 architecture divides the 4GiB virtual address space into 1024
4MiB-frames. This splitting is defined by the \emph{pagedirectory}. Each entry
of a pagedirectory is 4 bytes long, thus the pagedirectory is $4 \cdot 1024 =
4096$ Bytes long. Each of these \emph{pagedirectory entries} (PDEs), if present
(its \texttt{PRESENT}-flag is set), can either refer to a 4MiB physical page or
a pagetable dividing this virtual 4MiB frame further into 4KiB frames. A
\emph{pagetable} is again consisting of 1024 4-byte \emph{pagetable entries}
(PTEs), each corresponding to a 4KiB frame.

As newer IA32 CPU features like \emph{36 bit page size extension} (PSE-36) and
\emph{physical address extension} (PSE) are not used in case of the proposed
circumstances (see section \ref{ia32_config_options}), their reflection is
omitted here.  Furthermore it is not always possible to know from the physical
memory only, if these features are enabled.  A sample-installation of a system
to be attacked should give these informations. Also, PAE and PSE-36 are not yet
implemented in \texttt{liblinear}. PSE though (not PSE-36) is enabled with the
given options (and implemented), as one can determine by the use of 4MiB-pages.

For an extensive documentation of the IA32 architecture one should refer to the
\emph{Intel 64 and IA-32 Architectures Software Developer's Manual}
(\cite{IA32_SDM_1:2006}, \cite{IA32_SDM_2a:2006}, \cite{IA32_SDM_2b:2006},
\cite{IA32_SDM_3a:2006}, \cite{IA32_SDM_3b:2006}), especially
\cite{IA32_SDM_3a:2006}.



\subsection{Finding address translation tables}
\label{findingATT}

When accessing a range of memory via physical addressing, it is neccessary to
find address translation tables to make sence out of the vast, unsorted number
of pages. Typically, translation tables are not marked as such and as we can not
access the processor or the operating system to ask, where these are, we have to
search them. The following methods have proven themselves when being combined:
for all pages: make a quick guess if a page could be a pagedirectory
(\ref{ATTguess}) and if so, analyse this page more in detail
(\ref{ATTstatistics}):



\subsubsection{OS and architecture dependencies; typical address space layout}

\label{ATTguess} Obviously, address translation tables are architecture and
operating system specific; but within an architecture and an operating system,
they will often share data or specific patterns that are identifiable. For
instance, when searching for linux IA32 address translation tables, one can omit
searching the segment descriptor tables (see section \ref{linux_gdt}) and
concentrate on finding pagedirectories. There are several special patterns that
can be found in a typical pagedirectory of a linux process running on IA32.
Following is a layout of the typical virtual address space of a userspace
process:

\begin{itemize}

	\item \emph{code and heap} will be starting somewhere around
	\texttt{0x0800~0000}, consecutively following with a minor number of
	unused frames in between

	\item \emph{libraries} and \emph{custom mappings} will be mapped below
	\texttt{0xb800~0000}

	\item the \emph{userspace stack} will be mapped somewhere below
	\texttt{0xc000~0000}, possibly directly starting from
	\texttt{0xbfff~ffff}

	\item starting from \texttt{0xc000~0000} up to approx.
	\texttt{0xf800~0000} the ``lowmem'' (approx. lower physical 900 MiB of
	physical RAM) will be mapped

	\item the \emph{kernelspace stack} will be located somewhere in this
	lowmem

	\item several so far unidentified pages are mapped after
	\texttt{0xf800~0000}

	\item all \emph{unused frames} will have 4-byte entries consisting of
	zeroes (\texttt{0x00~00~00~00})

\end{itemize}

Stack- and memory randomization techniques like \emph{PaX} randomize the base
addresses of these locations a bit, but the general layout stays the same.

Besides searching pages that show non-zero values around these positions and
zero values elsewhere, it is much easier and faster to just check, if the
virtual address \texttt{0xc000~0000} maps to the physical address \texttt{0x0},
because typically the PDE for 4MiB-page no.\@ \texttt{0x300} will point to the
4MiB physical page at \texttt{0x0}. This test only requires reading the 4byte
PDE entry \texttt{0x300} and does sort out a vast majority of non-pagedirectory
pages.

Furthermore in the combination linux/IA32 we only have to search the lower 1GB
of RAM for pagetables (see first paragraph of section \ref{kerneluserdivision}).



\subsubsection{Matching via statistics: NCD (normalized compression distance)}

\label{ATTstatistics} The \emph{normalized information distance} (NID), a form
of parameterfree similarity distance measurement, can be understood as a
measurement for the minimal amount of changes required to change one information
into another one.  A NID of 1 means that two informations are totally unrelated;
a NID of 0 means that they are the same.  Due to its relation to the
\emph{Kolmogorov complexity} (a measurement for an information`s shortest
description in a fixed description language) it is incalculateable.  As an
approximation, it is possible to use data compressors instead of the Kolmogorov
complexity to measure the size of a minimal representation of information. The
resulting \emph{normalized compression distance} has proven to be useful in a
vast area of applications; for instance, it has shown its usefulness during
analysis of DNA sequences or languages for relatedness
(\cite{clustering_by_compression:2005}, \cite{similarity_matrix:2004}), MIDI
music files for relations in style and creator
(\cite{clustering_by_compression:2005}) and attack schemes of virii and worms
(\cite{analysing_worms_with_ncd:2006}).  For a detailed introduction to and
analysis of the NCD and sample applications, the reader may refer to
\cite{kolmogorov:1997} and the above texts.

As the NCD is only an approximation of the NID based on compression, its
resulting ``normalized'' value can be slightly larger that $1.0$ and will never
reach $0$.

\texttt{liblinear} uses the NCD to measure the distance between a known true
pagedirectory and a page of unknown data to determine whether this page could be
a pagedirectory. The NCD has been chosen, because it is a \emph{parameterfree}
measurement, i.e. it does not depend on specific, known structures of the data
in question. As different architectures will have significantly different
address translation schemes, even depending on the operating systems used, this
choice should be adequate. The \texttt{complearn}-toolkit
\footnote{\texttt{complearn}-toolkit:
\href{http://complearn.org/}{http://complearn.org/}} provides a suite of
functions for generating NCD distance matrixes between information, generating
relational trees from these and more.  As we only need to compare two pages,
this set of functions is far too big and the interface far too complex for this
application.  Thus, I implemented my own, very short version of the NCD
(\texttt{simple\_ncd()} in \texttt{liblinear/simple\_ncd.c}) using BZip2 as
compressor.


